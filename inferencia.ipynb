{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "\"\"\"\n",
    "# Define the model class based on the provided LIMU-BERT structure\n",
    "class LIMUBERTModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LIMUBERTModel, self).__init__()\n",
    "        self.embed = nn.Linear(input_dim, hidden_dim)\n",
    "        self.transformer = nn.Transformer(hidden_dim, nhead=8, num_encoder_layers=6)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "class LIMUBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LIMUBERTModel, self).__init__()\n",
    "        self.embed = nn.Linear(6, 72)  # Adjusted to match the saved model\n",
    "        self.transformer = nn.Transformer(d_model=72, nhead=8, num_encoder_layers=6)  # Adjusted to match the saved model\n",
    "        self.fc = nn.Linear(72, 72)  # Adjusted to match the saved model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def get_embeddings(self, x):\n",
    "        x = self.embed(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary\n",
    "model_path = 'saved/pretrain_base_hhar_20_120/hhar.pt'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Print the keys of the state dictionary\n",
    "print(state_dict.keys())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LIMUBERTModel:\n\tMissing key(s) in state_dict: \"embed.weight\", \"embed.bias\", \"transformer.encoder.layers.0.self_attn.in_proj_weight\", \"transformer.encoder.layers.0.self_attn.in_proj_bias\", \"transformer.encoder.layers.0.self_attn.out_proj.weight\", \"transformer.encoder.layers.0.self_attn.out_proj.bias\", \"transformer.encoder.layers.0.linear1.weight\", \"transformer.encoder.layers.0.linear1.bias\", \"transformer.encoder.layers.0.linear2.weight\", \"transformer.encoder.layers.0.linear2.bias\", \"transformer.encoder.layers.0.norm1.weight\", \"transformer.encoder.layers.0.norm1.bias\", \"transformer.encoder.layers.0.norm2.weight\", \"transformer.encoder.layers.0.norm2.bias\", \"transformer.encoder.layers.1.self_attn.in_proj_weight\", \"transformer.encoder.layers.1.self_attn.in_proj_bias\", \"transformer.encoder.layers.1.self_attn.out_proj.weight\", \"transformer.encoder.layers.1.self_attn.out_proj.bias\", \"transformer.encoder.layers.1.linear1.weight\", \"transformer.encoder.layers.1.linear1.bias\", \"transformer.encoder.layers.1.linear2.weight\", \"transformer.encoder.layers.1.linear2.bias\", \"transformer.encoder.layers.1.norm1.weight\", \"transformer.encoder.layers.1.norm1.bias\", \"transformer.encoder.layers.1.norm2.weight\", \"transformer.encoder.layers.1.norm2.bias\", \"transformer.encoder.layers.2.self_attn.in_proj_weight\", \"transformer.encoder.layers.2.self_attn.in_proj_bias\", \"transformer.encoder.layers.2.self_attn.out_proj.weight\", \"transformer.encoder.layers.2.self_attn.out_proj.bias\", \"transformer.encoder.layers.2.linear1.weight\", \"transformer.encoder.layers.2.linear1.bias\", \"transformer.encoder.layers.2.linear2.weight\", \"transformer.encoder.layers.2.linear2.bias\", \"transformer.encoder.layers.2.norm1.weight\", \"transformer.encoder.layers.2.norm1.bias\", \"transformer.encoder.layers.2.norm2.weight\", \"transformer.encoder.layers.2.norm2.bias\", \"transformer.encoder.layers.3.self_attn.in_proj_weight\", \"transformer.encoder.layers.3.self_attn.in_proj_bias\", \"transformer.encoder.layers.3.self_attn.out_proj.weight\", \"transformer.encoder.layers.3.self_attn.out_proj.bias\", \"transformer.encoder.layers.3.linear1.weight\", \"transformer.encoder.layers.3.linear1.bias\", \"transformer.encoder.layers.3.linear2.weight\", \"transformer.encoder.layers.3.linear2.bias\", \"transformer.encoder.layers.3.norm1.weight\", \"transformer.encoder.layers.3.norm1.bias\", \"transformer.encoder.layers.3.norm2.weight\", \"transformer.encoder.layers.3.norm2.bias\", \"transformer.encoder.layers.4.self_attn.in_proj_weight\", \"transformer.encoder.layers.4.self_attn.in_proj_bias\", \"transformer.encoder.layers.4.self_attn.out_proj.weight\", \"transformer.encoder.layers.4.self_attn.out_proj.bias\", \"transformer.encoder.layers.4.linear1.weight\", \"transformer.encoder.layers.4.linear1.bias\", \"transformer.encoder.layers.4.linear2.weight\", \"transformer.encoder.layers.4.linear2.bias\", \"transformer.encoder.layers.4.norm1.weight\", \"transformer.encoder.layers.4.norm1.bias\", \"transformer.encoder.layers.4.norm2.weight\", \"transformer.encoder.layers.4.norm2.bias\", \"transformer.encoder.layers.5.self_attn.in_proj_weight\", \"transformer.encoder.layers.5.self_attn.in_proj_bias\", \"transformer.encoder.layers.5.self_attn.out_proj.weight\", \"transformer.encoder.layers.5.self_attn.out_proj.bias\", \"transformer.encoder.layers.5.linear1.weight\", \"transformer.encoder.layers.5.linear1.bias\", \"transformer.encoder.layers.5.linear2.weight\", \"transformer.encoder.layers.5.linear2.bias\", \"transformer.encoder.layers.5.norm1.weight\", \"transformer.encoder.layers.5.norm1.bias\", \"transformer.encoder.layers.5.norm2.weight\", \"transformer.encoder.layers.5.norm2.bias\", \"transformer.encoder.norm.weight\", \"transformer.encoder.norm.bias\", \"transformer.decoder.layers.0.self_attn.in_proj_weight\", \"transformer.decoder.layers.0.self_attn.in_proj_bias\", \"transformer.decoder.layers.0.self_attn.out_proj.weight\", \"transformer.decoder.layers.0.self_attn.out_proj.bias\", \"transformer.decoder.layers.0.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.0.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.0.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.0.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.0.linear1.weight\", \"transformer.decoder.layers.0.linear1.bias\", \"transformer.decoder.layers.0.linear2.weight\", \"transformer.decoder.layers.0.linear2.bias\", \"transformer.decoder.layers.0.norm1.weight\", \"transformer.decoder.layers.0.norm1.bias\", \"transformer.decoder.layers.0.norm2.weight\", \"transformer.decoder.layers.0.norm2.bias\", \"transformer.decoder.layers.0.norm3.weight\", \"transformer.decoder.layers.0.norm3.bias\", \"transformer.decoder.layers.1.self_attn.in_proj_weight\", \"transformer.decoder.layers.1.self_attn.in_proj_bias\", \"transformer.decoder.layers.1.self_attn.out_proj.weight\", \"transformer.decoder.layers.1.self_attn.out_proj.bias\", \"transformer.decoder.layers.1.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.1.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.1.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.1.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.1.linear1.weight\", \"transformer.decoder.layers.1.linear1.bias\", \"transformer.decoder.layers.1.linear2.weight\", \"transformer.decoder.layers.1.linear2.bias\", \"transformer.decoder.layers.1.norm1.weight\", \"transformer.decoder.layers.1.norm1.bias\", \"transformer.decoder.layers.1.norm2.weight\", \"transformer.decoder.layers.1.norm2.bias\", \"transformer.decoder.layers.1.norm3.weight\", \"transformer.decoder.layers.1.norm3.bias\", \"transformer.decoder.layers.2.self_attn.in_proj_weight\", \"transformer.decoder.layers.2.self_attn.in_proj_bias\", \"transformer.decoder.layers.2.self_attn.out_proj.weight\", \"transformer.decoder.layers.2.self_attn.out_proj.bias\", \"transformer.decoder.layers.2.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.2.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.2.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.2.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.2.linear1.weight\", \"transformer.decoder.layers.2.linear1.bias\", \"transformer.decoder.layers.2.linear2.weight\", \"transformer.decoder.layers.2.linear2.bias\", \"transformer.decoder.layers.2.norm1.weight\", \"transformer.decoder.layers.2.norm1.bias\", \"transformer.decoder.layers.2.norm2.weight\", \"transformer.decoder.layers.2.norm2.bias\", \"transformer.decoder.layers.2.norm3.weight\", \"transformer.decoder.layers.2.norm3.bias\", \"transformer.decoder.layers.3.self_attn.in_proj_weight\", \"transformer.decoder.layers.3.self_attn.in_proj_bias\", \"transformer.decoder.layers.3.self_attn.out_proj.weight\", \"transformer.decoder.layers.3.self_attn.out_proj.bias\", \"transformer.decoder.layers.3.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.3.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.3.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.3.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.3.linear1.weight\", \"transformer.decoder.layers.3.linear1.bias\", \"transformer.decoder.layers.3.linear2.weight\", \"transformer.decoder.layers.3.linear2.bias\", \"transformer.decoder.layers.3.norm1.weight\", \"transformer.decoder.layers.3.norm1.bias\", \"transformer.decoder.layers.3.norm2.weight\", \"transformer.decoder.layers.3.norm2.bias\", \"transformer.decoder.layers.3.norm3.weight\", \"transformer.decoder.layers.3.norm3.bias\", \"transformer.decoder.layers.4.self_attn.in_proj_weight\", \"transformer.decoder.layers.4.self_attn.in_proj_bias\", \"transformer.decoder.layers.4.self_attn.out_proj.weight\", \"transformer.decoder.layers.4.self_attn.out_proj.bias\", \"transformer.decoder.layers.4.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.4.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.4.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.4.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.4.linear1.weight\", \"transformer.decoder.layers.4.linear1.bias\", \"transformer.decoder.layers.4.linear2.weight\", \"transformer.decoder.layers.4.linear2.bias\", \"transformer.decoder.layers.4.norm1.weight\", \"transformer.decoder.layers.4.norm1.bias\", \"transformer.decoder.layers.4.norm2.weight\", \"transformer.decoder.layers.4.norm2.bias\", \"transformer.decoder.layers.4.norm3.weight\", \"transformer.decoder.layers.4.norm3.bias\", \"transformer.decoder.layers.5.self_attn.in_proj_weight\", \"transformer.decoder.layers.5.self_attn.in_proj_bias\", \"transformer.decoder.layers.5.self_attn.out_proj.weight\", \"transformer.decoder.layers.5.self_attn.out_proj.bias\", \"transformer.decoder.layers.5.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.5.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.5.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.5.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.5.linear1.weight\", \"transformer.decoder.layers.5.linear1.bias\", \"transformer.decoder.layers.5.linear2.weight\", \"transformer.decoder.layers.5.linear2.bias\", \"transformer.decoder.layers.5.norm1.weight\", \"transformer.decoder.layers.5.norm1.bias\", \"transformer.decoder.layers.5.norm2.weight\", \"transformer.decoder.layers.5.norm2.bias\", \"transformer.decoder.layers.5.norm3.weight\", \"transformer.decoder.layers.5.norm3.bias\", \"transformer.decoder.norm.weight\", \"transformer.decoder.norm.bias\". \n\tUnexpected key(s) in state_dict: \"linear.weight\", \"linear.bias\", \"norm.gamma\", \"norm.beta\", \"decoder.weight\", \"decoder.bias\", \"transformer.embed.lin.weight\", \"transformer.embed.lin.bias\", \"transformer.embed.pos_embed.weight\", \"transformer.embed.norm.gamma\", \"transformer.embed.norm.beta\", \"transformer.attn.proj_q.weight\", \"transformer.attn.proj_q.bias\", \"transformer.attn.proj_k.weight\", \"transformer.attn.proj_k.bias\", \"transformer.attn.proj_v.weight\", \"transformer.attn.proj_v.bias\", \"transformer.proj.weight\", \"transformer.proj.bias\", \"transformer.norm1.gamma\", \"transformer.norm1.beta\", \"transformer.pwff.fc1.weight\", \"transformer.pwff.fc1.bias\", \"transformer.pwff.fc2.weight\", \"transformer.pwff.fc2.bias\", \"transformer.norm2.gamma\", \"transformer.norm2.beta\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m LIMUBERTModel()\n\u001b[1;32m     15\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msaved/pretrain_base_hhar_20_120/hhar.pt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 16\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict)\n\u001b[1;32m     17\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     19\u001b[0m \u001b[39m# Function to run inference\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/limu-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1047\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1048\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1050\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1052\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1053\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LIMUBERTModel:\n\tMissing key(s) in state_dict: \"embed.weight\", \"embed.bias\", \"transformer.encoder.layers.0.self_attn.in_proj_weight\", \"transformer.encoder.layers.0.self_attn.in_proj_bias\", \"transformer.encoder.layers.0.self_attn.out_proj.weight\", \"transformer.encoder.layers.0.self_attn.out_proj.bias\", \"transformer.encoder.layers.0.linear1.weight\", \"transformer.encoder.layers.0.linear1.bias\", \"transformer.encoder.layers.0.linear2.weight\", \"transformer.encoder.layers.0.linear2.bias\", \"transformer.encoder.layers.0.norm1.weight\", \"transformer.encoder.layers.0.norm1.bias\", \"transformer.encoder.layers.0.norm2.weight\", \"transformer.encoder.layers.0.norm2.bias\", \"transformer.encoder.layers.1.self_attn.in_proj_weight\", \"transformer.encoder.layers.1.self_attn.in_proj_bias\", \"transformer.encoder.layers.1.self_attn.out_proj.weight\", \"transformer.encoder.layers.1.self_attn.out_proj.bias\", \"transformer.encoder.layers.1.linear1.weight\", \"transformer.encoder.layers.1.linear1.bias\", \"transformer.encoder.layers.1.linear2.weight\", \"transformer.encoder.layers.1.linear2.bias\", \"transformer.encoder.layers.1.norm1.weight\", \"transformer.encoder.layers.1.norm1.bias\", \"transformer.encoder.layers.1.norm2.weight\", \"transformer.encoder.layers.1.norm2.bias\", \"transformer.encoder.layers.2.self_attn.in_proj_weight\", \"transformer.encoder.layers.2.self_attn.in_proj_bias\", \"transformer.encoder.layers.2.self_attn.out_proj.weight\", \"transformer.encoder.layers.2.self_attn.out_proj.bias\", \"transformer.encoder.layers.2.linear1.weight\", \"transformer.encoder.layers.2.linear1.bias\", \"transformer.encoder.layers.2.linear2.weight\", \"transformer.encoder.layers.2.linear2.bias\", \"transformer.encoder.layers.2.norm1.weight\", \"transformer.encoder.layers.2.norm1.bias\", \"transformer.encoder.layers.2.norm2.weight\", \"transformer.encoder.layers.2.norm2.bias\", \"transformer.encoder.layers.3.self_attn.in_proj_weight\", \"transformer.encoder.layers.3.self_attn.in_proj_bias\", \"transformer.encoder.layers.3.self_attn.out_proj.weight\", \"transformer.encoder.layers.3.self_attn.out_proj.bias\", \"transformer.encoder.layers.3.linear1.weight\", \"transformer.encoder.layers.3.linear1.bias\", \"transformer.encoder.layers.3.linear2.weight\", \"transformer.encoder.layers.3.linear2.bias\", \"transformer.encoder.layers.3.norm1.weight\", \"transformer.encoder.layers.3.norm1.bias\", \"transformer.encoder.layers.3.norm2.weight\", \"transformer.encoder.layers.3.norm2.bias\", \"transformer.encoder.layers.4.self_attn.in_proj_weight\", \"transformer.encoder.layers.4.self_attn.in_proj_bias\", \"transformer.encoder.layers.4.self_attn.out_proj.weight\", \"transformer.encoder.layers.4.self_attn.out_proj.bias\", \"transformer.encoder.layers.4.linear1.weight\", \"transformer.encoder.layers.4.linear1.bias\", \"transformer.encoder.layers.4.linear2.weight\", \"transformer.encoder.layers.4.linear2.bias\", \"transformer.encoder.layers.4.norm1.weight\", \"transformer.encoder.layers.4.norm1.bias\", \"transformer.encoder.layers.4.norm2.weight\", \"transformer.encoder.layers.4.norm2.bias\", \"transformer.encoder.layers.5.self_attn.in_proj_weight\", \"transformer.encoder.layers.5.self_attn.in_proj_bias\", \"transformer.encoder.layers.5.self_attn.out_proj.weight\", \"transformer.encoder.layers.5.self_attn.out_proj.bias\", \"transformer.encoder.layers.5.linear1.weight\", \"transformer.encoder.layers.5.linear1.bias\", \"transformer.encoder.layers.5.linear2.weight\", \"transformer.encoder.layers.5.linear2.bias\", \"transformer.encoder.layers.5.norm1.weight\", \"transformer.encoder.layers.5.norm1.bias\", \"transformer.encoder.layers.5.norm2.weight\", \"transformer.encoder.layers.5.norm2.bias\", \"transformer.encoder.norm.weight\", \"transformer.encoder.norm.bias\", \"transformer.decoder.layers.0.self_attn.in_proj_weight\", \"transformer.decoder.layers.0.self_attn.in_proj_bias\", \"transformer.decoder.layers.0.self_attn.out_proj.weight\", \"transformer.decoder.layers.0.self_attn.out_proj.bias\", \"transformer.decoder.layers.0.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.0.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.0.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.0.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.0.linear1.weight\", \"transformer.decoder.layers.0.linear1.bias\", \"transformer.decoder.layers.0.linear2.weight\", \"transformer.decoder.layers.0.linear2.bias\", \"transformer.decoder.layers.0.norm1.weight\", \"transformer.decoder.layers.0.norm1.bias\", \"transformer.decoder.layers.0.norm2.weight\", \"transformer.decoder.layers.0.norm2.bias\", \"transformer.decoder.layers.0.norm3.weight\", \"transformer.decoder.layers.0.norm3.bias\", \"transformer.decoder.layers.1.self_attn.in_proj_weight\", \"transformer.decoder.layers.1.self_attn.in_proj_bias\", \"transformer.decoder.layers.1.self_attn.out_proj.weight\", \"transformer.decoder.layers.1.self_attn.out_proj.bias\", \"transformer.decoder.layers.1.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.1.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.1.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.1.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.1.linear1.weight\", \"transformer.decoder.layers.1.linear1.bias\", \"transformer.decoder.layers.1.linear2.weight\", \"transformer.decoder.layers.1.linear2.bias\", \"transformer.decoder.layers.1.norm1.weight\", \"transformer.decoder.layers.1.norm1.bias\", \"transformer.decoder.layers.1.norm2.weight\", \"transformer.decoder.layers.1.norm2.bias\", \"transformer.decoder.layers.1.norm3.weight\", \"transformer.decoder.layers.1.norm3.bias\", \"transformer.decoder.layers.2.self_attn.in_proj_weight\", \"transformer.decoder.layers.2.self_attn.in_proj_bias\", \"transformer.decoder.layers.2.self_attn.out_proj.weight\", \"transformer.decoder.layers.2.self_attn.out_proj.bias\", \"transformer.decoder.layers.2.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.2.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.2.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.2.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.2.linear1.weight\", \"transformer.decoder.layers.2.linear1.bias\", \"transformer.decoder.layers.2.linear2.weight\", \"transformer.decoder.layers.2.linear2.bias\", \"transformer.decoder.layers.2.norm1.weight\", \"transformer.decoder.layers.2.norm1.bias\", \"transformer.decoder.layers.2.norm2.weight\", \"transformer.decoder.layers.2.norm2.bias\", \"transformer.decoder.layers.2.norm3.weight\", \"transformer.decoder.layers.2.norm3.bias\", \"transformer.decoder.layers.3.self_attn.in_proj_weight\", \"transformer.decoder.layers.3.self_attn.in_proj_bias\", \"transformer.decoder.layers.3.self_attn.out_proj.weight\", \"transformer.decoder.layers.3.self_attn.out_proj.bias\", \"transformer.decoder.layers.3.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.3.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.3.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.3.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.3.linear1.weight\", \"transformer.decoder.layers.3.linear1.bias\", \"transformer.decoder.layers.3.linear2.weight\", \"transformer.decoder.layers.3.linear2.bias\", \"transformer.decoder.layers.3.norm1.weight\", \"transformer.decoder.layers.3.norm1.bias\", \"transformer.decoder.layers.3.norm2.weight\", \"transformer.decoder.layers.3.norm2.bias\", \"transformer.decoder.layers.3.norm3.weight\", \"transformer.decoder.layers.3.norm3.bias\", \"transformer.decoder.layers.4.self_attn.in_proj_weight\", \"transformer.decoder.layers.4.self_attn.in_proj_bias\", \"transformer.decoder.layers.4.self_attn.out_proj.weight\", \"transformer.decoder.layers.4.self_attn.out_proj.bias\", \"transformer.decoder.layers.4.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.4.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.4.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.4.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.4.linear1.weight\", \"transformer.decoder.layers.4.linear1.bias\", \"transformer.decoder.layers.4.linear2.weight\", \"transformer.decoder.layers.4.linear2.bias\", \"transformer.decoder.layers.4.norm1.weight\", \"transformer.decoder.layers.4.norm1.bias\", \"transformer.decoder.layers.4.norm2.weight\", \"transformer.decoder.layers.4.norm2.bias\", \"transformer.decoder.layers.4.norm3.weight\", \"transformer.decoder.layers.4.norm3.bias\", \"transformer.decoder.layers.5.self_attn.in_proj_weight\", \"transformer.decoder.layers.5.self_attn.in_proj_bias\", \"transformer.decoder.layers.5.self_attn.out_proj.weight\", \"transformer.decoder.layers.5.self_attn.out_proj.bias\", \"transformer.decoder.layers.5.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.5.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.5.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.5.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.5.linear1.weight\", \"transformer.decoder.layers.5.linear1.bias\", \"transformer.decoder.layers.5.linear2.weight\", \"transformer.decoder.layers.5.linear2.bias\", \"transformer.decoder.layers.5.norm1.weight\", \"transformer.decoder.layers.5.norm1.bias\", \"transformer.decoder.layers.5.norm2.weight\", \"transformer.decoder.layers.5.norm2.bias\", \"transformer.decoder.layers.5.norm3.weight\", \"transformer.decoder.layers.5.norm3.bias\", \"transformer.decoder.norm.weight\", \"transformer.decoder.norm.bias\". \n\tUnexpected key(s) in state_dict: \"linear.weight\", \"linear.bias\", \"norm.gamma\", \"norm.beta\", \"decoder.weight\", \"decoder.bias\", \"transformer.embed.lin.weight\", \"transformer.embed.lin.bias\", \"transformer.embed.pos_embed.weight\", \"transformer.embed.norm.gamma\", \"transformer.embed.norm.beta\", \"transformer.attn.proj_q.weight\", \"transformer.attn.proj_q.bias\", \"transformer.attn.proj_k.weight\", \"transformer.attn.proj_k.bias\", \"transformer.attn.proj_v.weight\", \"transformer.attn.proj_v.bias\", \"transformer.proj.weight\", \"transformer.proj.bias\", \"transformer.norm1.gamma\", \"transformer.norm1.beta\", \"transformer.pwff.fc1.weight\", \"transformer.pwff.fc1.bias\", \"transformer.pwff.fc2.weight\", \"transformer.pwff.fc2.bias\", \"transformer.norm2.gamma\", \"transformer.norm2.beta\". "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the configuration\n",
    "with open('dataset/data_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Adjust based on the specific dataset you're working with\n",
    "dataset_name = 'hhar_20_120'\n",
    "#input_dim = config[dataset_name]['dimension']\n",
    "#hidden_dim = 72  # This should match your model's configuration\n",
    "#output_dim = len(config[dataset_name]['activity_label'])\n",
    "\n",
    "# Load the pre-trained model\n",
    "#model = LIMUBERTModel(input_dim, hidden_dim, output_dim)\n",
    "model = LIMUBERTModel()\n",
    "\n",
    "model_path = 'saved/pretrain_base_hhar_20_120/hhar.pt'\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Function to run inference\n",
    "def run_inference(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_tensor = torch.from_numpy(data).float()\n",
    "        output = model(data_tensor)\n",
    "        predictions = torch.argmax(output, dim=-1)\n",
    "    return predictions.numpy()\n",
    "\n",
    "def extract_segment(data, start_index, seq_len=120):\n",
    "    \"\"\"\n",
    "    Extracts a 6-second segment from the data starting from start_index.\n",
    "    \n",
    "    Parameters:\n",
    "        data (np.array): The dataset array of shape (N, W, F).\n",
    "        start_index (int): The starting index for the segment.\n",
    "        seq_len (int): The sequence length (default is 120).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: A segment of shape (1, seq_len, F).\n",
    "    \"\"\"\n",
    "    end_index = start_index + 1\n",
    "    segment = data[start_index:end_index, :seq_len, :]\n",
    "    return segment\n",
    "\n",
    "# Load your data\n",
    "data_path = 'dataset/hhar/data_20_120.npy'\n",
    "data = np.load(data_path)\n",
    "\n",
    "# Extract a 6-second segment starting from index 0\n",
    "start_index = 0\n",
    "segment = extract_segment(data, start_index)\n",
    "\n",
    "# Run inference on the extracted segment\n",
    "predictions = run_inference(model, segment)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMUBERTModel(\n",
       "  (embed): Linear(in_features=6, out_features=72, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=72, out_features=72, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
       "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=72, out_features=72, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "model = LIMUBERTModel()\n",
    "\n",
    "# Path to your model file\n",
    "model_path = 'saved/pretrain_base_hhar_20_120/hhar.pt'\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9166, 120, 6)\n"
     ]
    }
   ],
   "source": [
    "# Function to run inference\n",
    "def run_inference(model, data_segment):\n",
    "    # Ensure data_segment is a torch tensor\n",
    "    if not isinstance(data_segment, torch.Tensor):\n",
    "        data_segment = torch.tensor(data_segment, dtype=torch.float32)\n",
    "    \n",
    "    # Add batch dimension if necessary\n",
    "    if len(data_segment.shape) == 2:\n",
    "        data_segment = data_segment.unsqueeze(0)\n",
    "    \n",
    "    # Prepare tgt tensor\n",
    "    tgt = data_segment.clone()  # Modify this if needed based on model's requirements\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data_segment, tgt)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def extract_segment(data, start_index, seq_len=120):\n",
    "    \"\"\"\n",
    "    Extracts a 6-second segment from the data starting from start_index.\n",
    "    \n",
    "    Parameters:\n",
    "        data (np.array): The dataset array of shape (N, W, F).\n",
    "        start_index (int): The starting index for the segment.\n",
    "        seq_len (int): The sequence length (default is 120).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: A segment of shape (1, seq_len, F).\n",
    "    \"\"\"\n",
    "    end_index = start_index + 1\n",
    "    segment = data[start_index:end_index, :seq_len, :]\n",
    "    return segment\n",
    "\n",
    "# Load your data\n",
    "data_path = 'dataset/hhar/data_20_120.npy'\n",
    "data = np.load(data_path)\n",
    "print(data.shape)\n",
    "# Extract a 6-second segment starting from index 0\n",
    "start_index = 0\n",
    "segment = extract_segment(data, start_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_inference(model, data)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(model, data_segment)\u001b[0m\n\u001b[1;32m     12\u001b[0m tgt \u001b[39m=\u001b[39m data_segment\u001b[39m.\u001b[39mclone()  \u001b[39m# Modify this if needed based on model's requirements\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 15\u001b[0m     output \u001b[39m=\u001b[39m model(data_segment, tgt)\n\u001b[1;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/limu-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "run_inference(model, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "limu-py38",
   "language": "python",
   "name": "limu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
